SYSTÈME DE TRADING ALGORITHMIQUE SAC EUR/USD - SPÉCIFICATIONS TECHNIQUES

VERSION: 2.0
OBJECTIF: Trading algorithmique EUR/USD 5 minutes via Soft Actor-Critic

================================================================================
1. VUE D'ENSEMBLE
================================================================================

Trading autonome EUR/USD sur timeframe 5 minutes avec:
- 3 agents SAC en ensemble
- Auxiliary task learning (autoencodeur + K-Means)
- Meta-controller neural pour agrégation
- HMM pour détection de régime (low/high volatility)
- 30 features techniques multi-timeframe
- Risk management strict: 2% max par trade
- Stop-loss: 2×ATR, Take-profit: 2:1 risk/reward
- Drawdown max acceptable: 15%

Contraintes:
- Données: OHLC seulement (pas de volume réel)
- Broker: IC Markets EU, MT5
- Leverage max: 30:1 (régulation EU)
- Coûts de transaction: Modèle décomposé réaliste (2.5-4.5 bps total)

================================================================================
2. DONNÉES
================================================================================

Source: GitHub philipperemy/FX-1-Minute-Data
Format: CSV (timestamp, open, high, low, close)
Fréquence: 1 minute → agrégé en 5 minutes

Paires utilisées (10 + 2 indices):
1. EUR/USD (principale)
2. USD/JPY
3. GBP/USD
4. USD/CAD
5. USD/SEK
6. USD/CHF
7. EUR/GBP
8. EUR/JPY
9. USD/CHF
10. USD/CAD
11. SPX/USD (S&P 500)
12. XAU/USD (Gold)

Agrégation 1min → 5min (OHLC standard):
- Open: première valeur close dans fenêtre 5min
- High: max de tous les high
- Low: min de tous les low
- Close: dernière valeur close dans fenêtre 5min

Nettoyage:
- Outliers: Returns > 5σ clippés à ±5σ
- Validation OHLC: high >= max(open,close), low <= min(open,close)
- Alignement temporel: intersection timestamps communs toutes paires

Split temporel:
- Training: 2011-01-01 → 2023-12-31 (13 ans)
- Validation: 2019-01-01 → 2023-12-31 (5 ans, overlap intentionnel)
- Test OOS: 2024-01-01 → 2025-01-31 (JAMAIS touché avant validation finale)

Gestion marchés fermés:
- Vérifier que TOUTES les paires ont des données au timestamp actuel
- Si une seule paire manquante ou prix stable → pause trading
- Reprendre uniquement quand toutes les paires actives

================================================================================
3. FEATURE ENGINEERING (30 features)
================================================================================

RÈGLE CRITIQUE: Zéro look-ahead bias
- Tous calculs rolling: shift(1) avant application
- Expanding window: exclut observation courante
- Corrélations: les 2 séries shift(1) avant calcul

GROUPE 1: EUR/USD DIRECT (10 features)

Returns multi-timeframe:
1. return_5min = (close_t - close_t-1) / close_t-1
2. return_1h = (close_t - close_t-12) / close_t-12
3. return_4h = (close_t - close_t-48) / close_t-48
4. return_1d = (close_t - close_t-288) / close_t-288

Momentum:
5. rsi_14 = RSI(14) / 100  [range 0-1, déjà normalisé]
6. macd_histogram = MACD(12,26,9) histogram

Volatilité:
7. atr_14 = ATR(14) / close  [normalisé en % du prix]
8. parkinson_vol = sqrt(log(high/low)² / (4*log(2)))
9. bb_width = (BB_upper - BB_lower) / BB_middle  [Bollinger Bands SMA(20)±2σ]

Microstructure:
10. hl_range = (high - low) / close

GROUPE 2: DXY SYNTHETIC INDEX (5 features)

Calcul DXY:
DXY = 50.14348112 × (1/EURUSD)^0.576 × USDJPY^0.136 × (1/GBPUSD)^0.119 
                   × USDCAD^0.091 × USDSEK^0.042 × USDCHF^0.036

11. dxy_return_1h
12. dxy_return_4h
13. dxy_rsi_14
14. dxy_atr_14
15. corr_eurusd_dxy_60d = correlation rolling 60 jours EUR/USD vs DXY

GROUPE 3: CROSS-PAIRS (6 features)

16. usdjpy_return_1h
17. usdjpy_rsi_14
18. eurgbp_return_1h
19. eurgbp_rsi_14
20. eurjpy_return_1h
21. eurjpy_rsi_14

GROUPE 4: RISK INDICATORS (2 features)

22. spx_atr_14 = ATR(14) S&P 500 normalisé (proxy VIX)
23. xauusd_return_1h = Momentum Gold 1h (risk-off indicator)

GROUPE 5: TEMPORAL (7 features)

Encoding cyclique pour éviter discontinuités:
24. hour_sin = sin(2π × hour / 24)
25. hour_cos = cos(2π × hour / 24)
26. day_sin = sin(2π × day / 7)
27. day_cos = cos(2π × day / 7)

Sessions binaires:
28. session_european = 1 si 07h-16h UTC, 0 sinon
29. session_us = 1 si 13h-22h UTC, 0 sinon
30. session_asian = 1 si 23h-09h UTC, 0 sinon

================================================================================
4. NORMALISATION
================================================================================

Méthode: Expanding Window Z-Score avec clipping

Formule:
normalized_t = clip((value_t - mean_{0:t-1}) / (std_{0:t-1} + 1e-8), -5, 5)

Où:
- mean_{0:t-1} = moyenne de TOUTES valeurs jusqu'à t-1 (EXCLU t)
- std_{0:t-1} = écart-type jusqu'à t-1 (EXCLU t)
- Clipping [-5, 5] pour stabilité

Features NON normalisées:
- RSI (déjà [0,100], ramener à [0,1] via /100)
- Sessions binaires (déjà [0,1])

Implémentation:
1. Calculer feature brute avec shift(1)
2. Appliquer expanding().mean() et expanding().std()
3. Shift(1) additionnel sur mean/std
4. Normaliser
5. Clip [-5, 5]
6. fillna(0) pour warmup period

================================================================================
5. ENVIRONNEMENT GYM
================================================================================

Observation space: Box(30,) continuous [-10, 10]
Action space: Box(1,) continuous [-1, 1]

Action interpretation:
-1.0 = Maximum short position
 0.0 = Flat (pas de position)
+1.0 = Maximum long position

Position sizing (risk-based):
1. ATR_current = ATR(14) actuel
2. SL_distance = 2 × ATR_current
3. Risk_dollars = 2% × equity
4. Position_size = Risk_dollars / (SL_distance_pips × pip_value)
5. Position_final = action × Position_size

Validation contraintes:
- Leverage: position × 100k / equity < 30
- Minimum: position >= 0.01 lots
- Si violations: ajuster position

Transaction costs (Modèle décomposé réaliste):
1. Spread de base: 0.5-1.0 bps (EUR/USD, variable par heure)
2. Slippage: 1-2 bps baseline pour barres 5min
3. Market impact: 0.5-1.5 bps selon taille position
4. TOTAL RÉALISTE: 2.5-4.5 bps par direction (open ou close)

Stop-Loss et Take-Profit:
Pour LONG:
  SL = entry_price - (2 × ATR_14)
  TP = entry_price + (2 × SL_distance) = entry + 4×ATR

Pour SHORT:
  SL = entry_price + (2 × ATR_14)
  TP = entry_price - (4 × ATR_14)

Risk:Reward = 1:2

Margin Call:
Si equity < 20% × initial_capital:
  → Fermer toutes positions immédiatement
  → Episode terminé
  → Reward pénalité = -10.0

Épisodes:
- Longueur par défaut: 3000 bars (~10 jours trading)
- Longueurs variables: échantillonnées de [1000, 3000, 6000] 
  avec probabilités [0.3, 0.5, 0.2]
- Start: aléatoire dans dataset (random start position)
- Terminaison hybride:
  * Longueur fixe atteinte OU
  * Drawdown > 20% 
- Reset: nouvel épisode à position aléatoire

Métriques trackées durant épisode:
- equity_curve: valeur compte chaque step
- returns_buffer: returns step-by-step
- trades: historique (entry, exit, PnL)
- daily_pnl: P&L journalier
- position_history: évolution positions

Calculs fin épisode:
- Sharpe Ratio
- Sortino Ratio
- Calmar Ratio
- Max Drawdown
- Win Rate
- Profit Factor
- Expectancy

================================================================================
6. AGENTS SAC
================================================================================

Architecture Soft Actor-Critic avec Adaptive Normalization (AN-SAC):

Actor (Policy Network):
  Input: state (30)
  Hidden: [256, 256] avec ReLU
  Spectral Normalization: Toutes couches cachées
  Layer Normalization: Après spectral norm, avant activation
  Dropout: 0.1 sur couches feature extraction
  Output: mean (1) et log_std (1)
  Action: sample N(mean, std) puis tanh → [-1, 1]

Critic Networks (2 Q-functions):
  Input: state (30) + action (1) = 31
  Hidden: [256, 256] avec ReLU
  Spectral Normalization: Toutes couches cachées
  Layer Normalization: Après spectral norm, avant activation
  Dropout: 0.2-0.3 sur couches cachées
  Output: Q-value (1)

Target Networks: copies de Q₁ et Q₂
  Soft update: θ' ← τ×θ + (1-τ)×θ'
  τ = 0.005 (standard)

Replay Buffer:
  Capacité: 100,000 transitions
  Format: (state, action, reward, next_state, done)
  Sampling: Recency-weighted avec exponential decay
    - age_weights = exp(-0.00005 × ages)
    - Expériences récentes 2-3× plus susceptibles d'être échantillonnées
  Stratification: 20% trades gagnants, 20% perdants, 60% neutres
  Trimming: Tous les 50k steps, supprimer les 30% plus vieux
  Batch size: 512 (optimisé pour stabilité)

Hyperparamètres:
  Learning rates: 3e-4 (actor, critic)
  Entropy coefficient: 'auto' avec target_entropy = -1 (automatic tuning)
  Batch size: 512
  Discount γ: varie par agent
  Warmup: 10,000 steps (actions aléatoires)
  Update ratio: 1:1 (1 gradient update par step environnement)

Régularisation:
  Weight decay: 1e-3 pour critics
  Dropout: 0.2-0.3 pour critics, 0.1 pour actors
  Spectral normalization: Toutes linear layers (sauf input/output)
  Layer normalization: Après spectral norm, avant activation

Configuration 3 agents:

Agent 1 "Short-term":
  Gamma: 0.93 (horizon ~14 steps = 70 minutes)
  Architecture: [256, 256]
  LR: 3e-4
  Max position: 2.0 (200% capital)
  Focus: Scalping, patterns court terme

Agent 2 "Medium-term Balanced":
  Gamma: 0.95 (horizon ~20 steps = 100 minutes)
  Architecture: [256, 128]
  LR: 3e-4
  Max position: 1.5 (plus conservateur)
  Focus: Trading moyen terme

Agent 3 "Swing Adaptive":
  Gamma: 0.97 (horizon ~33 steps = 165 minutes)
  Architecture: [128, 128]
  LR: 2e-4
  Max position: 2.0
  Focus: Swing trading, patterns long terme
  Particularité: Q-functions séparées par régime HMM

Adaptive Normalization (AN-SAC):
  Reward normalization dynamique basée sur trajectoire de performance
  Beta distribution initialization pour stabilité améliorée
  Ajustement automatique des paramètres selon performance agent

Training loop:
Pour chaque step:
  1. Actor produit action
  2. Execute dans environment
  3. Store transition dans buffer
  4. Sample batch 512 depuis buffer (recency-weighted)
  5. Update Critic (minimize TD error)
  6. Update Actor (maximize Q + entropy)
  7. Update Alpha automatiquement (entropy tuning)
  8. Adaptive reward normalization (AN-SAC)
  9. Soft update target networks
  10. Log metrics tous les 1000 steps
  11. Save checkpoint tous les 50,000 steps

Total training: 800,000 steps par agent
Épisodes par agent: ~266 épisodes (si 3000 bars moyens)
Durée estimée: 2-4h par agent sur V100/A100

================================================================================
7. AUXILIARY TASK LEARNING
================================================================================

Implémentation: Autoencodeur + K-Means pour reconnaissance de patterns

Architecture Autoencodeur:
  Input: séquence de prix (lookback 50 bars)
  Encoder: [256, 128, 64]
  Latent space: 32 dimensions
  Decoder: [64, 128, 256]
  Output: reconstruction séquence prix

K-Means Clustering:
  K = 5 clusters (régimes de marché)
  Features: latent representations de l'autoencodeur
  Labels: 0=ranging, 1=trending_up, 2=trending_down, 
         3=high_volatility, 4=low_volatility

Loss Function Combinée:
  total_loss = 0.80 × RL_loss + 0.20 × auxiliary_loss
  
  Où:
  RL_loss = SAC standard loss (actor + critic + entropy)
  auxiliary_loss = reconstruction_loss + classification_loss
  
  reconstruction_loss = MSE(input_sequence, reconstructed_sequence)
  classification_loss = CrossEntropy(predicted_cluster, true_cluster)

Training Auxiliaire:
  - Pré-entraîner autoencodeur sur 100k séquences de prix
  - Figer encoder après pré-entraînement
  - Utiliser latent representations comme features additionnelles
  - K-Means update tous les 10k steps
  - Classification loss weight decay de 0.2 → 0.05 durant training

Bénéfices:
  - Amélioration de 10-15% d'efficacité d'échantillonnage
  - Meilleur modélisation de la reward function
  - Reconnaissance de patterns améliorée
  - Généralisation supérieure sur OOS data

================================================================================
8. HMM RÉGIME DETECTION
================================================================================

Type: Gaussian HMM
États: 2 (low_volatility, high_volatility)
Covariance: "full"

Features pour HMM (3 features):
1. Returns EUR/USD
2. Realized volatility: std(returns) rolling 20
3. Range: (high - low) / close

Training:
- Algorithme: Expectation-Maximization
- Données: TOUT le training set (2011-2023)
- Itérations: 100

Identification états:
high_vol_state = argmax(trace(Covariance_i))
low_vol_state = 1 - high_vol_state

Utilisation:

Historique (Viterbi):
states_sequence = hmm.predict(features)
→ [0,0,0,1,1,1,0,0,...]

Temps réel (Forward):
regime_probs = hmm.predict_proba(recent_features[-100:])
current_probs = regime_probs[-1]
→ [P(low_vol), P(high_vol)]

Intégration avec SAC:

Agents 1 et 2:
  Ajouter 2 features au state:
  - is_low_vol (binaire)
  - is_high_vol (binaire)
  State devient 32 dimensions

Agent 3:
  Q-functions séparées:
  - Q_low pour régime low_vol
  - Q_high pour régime high_vol
  Switch selon régime actuel
  Training séparé par régime

Déclencheurs d'adaptation basés sur régime:
  - Haute volatilité détectée: α ← α × 1.5 (plus d'exploration)
  - Transition de régime: position_sizing ← position_sizing × 0.7
  - Volatilité extrême (top 5%): désactiver trading
  - Nouveau régime hors distribution: trigger retrain

================================================================================
9. REWARD FUNCTION
================================================================================

Combinaison dense + terminal:
  final_reward = 0.40 × dense_reward + 0.60 × terminal_reward

DENSE REWARD (chaque step):

dense_reward = 0.30 × R_return + 0.30 × R_dsr + 0.20 × R_downside 
             + 0.15 × R_cost + 0.05 × R_position_change

Composante 1 - Returns (30%):
R_return = (equity_t - equity_t-1) / initial_capital

Composante 2 - Differential Sharpe Ratio (30%):
A_t = (1-η)×A_t-1 + η×r_t  [η=0.001]
B_t = (1-η)×B_t-1 + η×r_t²
delta_A = r_t - A_t
delta_B = r_t² - B_t
numerator = B_t × delta_A - 0.5 × A_t × delta_B
denominator = (B_t - A_t²)^1.5 + 1e-8
R_dsr = clip(numerator / denominator, -3, 3)

Composante 3 - Downside Penalty (20%):
recent_returns = returns_buffer[-50:]
negative_returns = [r for r in recent_returns if r < 0]
if negative_returns:
  R_downside = -std(negative_returns) × 10.0
else:
  R_downside = 0.0

Composante 4 - Transaction Costs (15%):
position_change = |target_position - current_position|
if position_change > 0.01 × equity:
  cost = position_change × total_cost_model(hour, volatility, size)
  R_cost = -cost / initial_capital
else:
  R_cost = 0.0

Composante 5 - Position Change Penalty (5%):
n_trades_today = count(trades derniers 288 steps)
if n_trades_today > 10:
  R_position = -(n_trades_today - 10)² × 0.0005
else:
  R_position = -position_change × 0.001

TERMINAL REWARD (fin épisode):

terminal_reward = 0.35 × R_sortino + 0.25 × R_calmar 
                + 0.25 × R_drawdown + 0.15 × R_expectancy

Composante 1 - Sortino (35%):
mean_return = mean(returns_episode)
downside_returns = [r for r in returns if r < 0]
downside_std = std(downside_returns)
sortino = mean_return / downside_std
R_sortino = (sortino - 1.5) / 0.5

Composante 2 - Calmar (25%):
annual_return = mean_return × 252 × 288
max_dd = max_drawdown(equity_curve)
calmar = annual_return / max_dd
R_calmar = (calmar - 2.0) / 0.5

Composante 3 - Drawdown Penalty (25%):
if max_dd < 0.05:
  R_drawdown = 0.0
elif max_dd < 0.10:
  R_drawdown = -0.02 × max_dd
else:
  R_drawdown = -0.15 × max_dd²  [quadratique pour DD>10%]

Composante 4 - Expectancy (15%):
trades = all_closed_trades_episode
winning = [p for p in trade_pnls if p > 0]
losing = [p for p in trade_pnls if p < 0]
if len(trades) > 10:
  win_rate = len(winning) / len(trades)
  avg_win = mean(winning)
  avg_loss = mean(abs(losing))
  expectancy = win_rate × avg_win - (1 - win_rate) × avg_loss
  R_expectancy = (expectancy - 20) / 10
else:
  R_expectancy = -1.0  [pénalité si <10 trades]

================================================================================
10. META-CONTROLLER
================================================================================

Architecture:
  Input: state (30) + agent_confidences (3) = 33
  Hidden: [128, 64]
  Output: weights (3)
  Activation output: Softmax (sum weights = 1)

Agent confidences:
Pour chaque agent i:
  confidence_i = -abs(Q_value_i - mean(Q_values))
  [Plus Q proche de la moyenne, plus confiant]

Training:
1. Collecter N=50 épisodes avec ensemble
2. Pour chaque step, calculer hindsight optimal weights:
   optimal_weights[t] = softmax(-abs(agent_returns[t] - best_return[t]))
3. Train meta-controller:
   Loss = MSE(predicted_weights, optimal_weights)
4. Optimizer: Adam, LR=1e-4

Agrégation finale:
action_ensemble = Σ(weights[i] × actions[i])

================================================================================
11. VALIDATION
================================================================================

Walk-Forward Validation:
  Initial train: 24 mois
  Test window: 3 mois
  Step: 3 mois (expanding window)
  Itérations: 40

Walk-Forward Efficiency:
  WFE = Sharpe_OOS / Sharpe_IS
  Acceptable si WFE > 0.5

Tests statistiques:

Deflated Sharpe Ratio (DSR):
  DSR = (Sharpe_obs - E[max_Sharpe_null]) / SE[Sharpe]
  N = 50 (configurations testées)
  Acceptable si DSR > 0.5

Probabilistic Sharpe Ratio (PSR):
  PSR = probabilité que Sharpe_true > 0
  Ajuste pour skewness et kurtosis
  Acceptable si PSR > 0.80

Probability Backtest Overfitting (PBO):
  Compare median(Sharpe_OOS) vs Sharpe_OOS[best_IS]
  PBO < 0.5 acceptable

Bootstrap CI:
  1000 resamples avec remplacement
  95% CI doit exclure zéro

Stress tests (7 scénarios):
1. High volatility 2× et 3×
2. Strong trending market (+/-)
3. Flash crash (-5% en 10 bars)
4. Liquidity crisis (spread ×5)
5. Black swan (5σ events)
6. Correlation breakdown (EUR/USD vs DXY inverted)
7. Extended drawdown (20% sur 1000 bars)

Critères succès:
- Aucun margin call
- Sharpe > 0.3 dans 5/7 scénarios
- Max DD < 30% tous scénarios

Test OOS final (2024-2025):
  JAMAIS touché avant
  Critères minimum:
    - Sharpe > 0.8
    - Sortino > 1.2
    - Max DD < 15%
    - Win rate > 45%

================================================================================
12. PRODUCTION
================================================================================

MT5 Connector:
- Connexion via Python MT5 API
- Authentification: account, password, server
- Get current prices (bid/ask)
- Get account info (balance, equity, margin)
- Open/close/modify positions
- Reconnection automatique si déconnexion

Order Manager:
- Convertit signals → ordres MT5
- Position sizing risk-based
- Set SL/TP
- Execute avec retry logic
- Log tous trades

Risk Manager:
- Monitor equity temps réel
- Daily loss limit: 5%
- Max drawdown: 15%
- Peak equity tracking
- Kill switch si limites dépassées

Trading Loop:
while trading_enabled:
  # 1. Get data
  current_data = get_last_N_bars_MT5(n=100)
  
  # 2. Verify toutes paires actives
  if not all_pairs_active(current_data):
    log("Marché fermé, pause trading")
    sleep(60)
    continue
  
  # 3. Calculate features
  features = feature_engineer.calculate(current_data)
  state = features[-1]
  
  # 4. Detect regime
  regime = hmm_detector.get_current_regime(current_data)
  
  # 5. Get ensemble action
  action = meta_ensemble.get_action(state, regime)
  
  # 6. Calculate position
  position_size, sl, tp = position_sizer.calculate(
    equity, current_price, atr, sign(action)
  )
  
  # 7. Validate risks
  if risk_manager.validate_trade(position_size, equity):
    order_manager.execute_signal(action, price, sl, tp, position_size)
  
  # 8. Update metrics
  risk_manager.update_equity(current_equity)
  
  # 9. Emit to web interface
  socketio.emit('update', metrics)
  
  # 10. Sleep until next 5min bar
  sleep_until_next_bar()

Web Interface (Flask + SocketIO):
- Dashboard temps réel
- Control buttons (Start/Stop/Emergency)
- Equity curve live
- Performance metrics
- Current position
- Trade history
- Logs streaming
- Configuration editor
- Model selection/loading
- Re-training trigger

Kill Switch (3 niveaux):
1. Soft Stop: stop new positions, keep current
2. Hard Stop: close all + stop loop
3. Emergency: immediate close all + disconnect

Triggers automatiques:
- Daily loss > 5%
- Drawdown > 15%
- Equity < 20% initial
- Erreur critique

Online Learning (Stratégie intégrée):
MICRO-RETRAINS (Hebdomadaires):
  Fréquence: Tous les 7 jours
  Données: Derniers 90 jours seulement
  Learning rate: 1e-5 (réduit pour fine-tuning)
  Steps: 50,000
  Process:
    1. Collecter données récentes incluant trades live
    2. Load production model comme point de départ
    3. Fine-tune avec LR réduit
    4. Validate sur 7 derniers jours
    5. Si amélioration: déployer en shadow mode
    6. A/B test: 10% capital sur nouveau, 90% sur ancien
    7. Si performance maintenue 1 semaine: full deployment

FULL RETRAINS (Trimestriels):
  Fréquence: Tous les 3 mois
  Données: Dataset complet élargi
  Process:
    1. Stop trading (weekend de préférence)
    2. Download tous les trades production + nouvelles données MT5
    3. Ré-optimiser hyperparamètres si nécessaire
    4. Entraîner 5-10 candidats avec seeds différentes
    5. Sélectionner meilleur sur validation Sharpe
    6. Shadow mode (paper trading) pendant 2 semaines complètes
    7. Comparer performance shadow vs production
    8. Gradual rollout: 10% → 25% → 50% → 100% sur 4 semaines
    9. Maintenir rollback instantané disponible

RÈGLE ABSOLUE: Ne JAMAIS retrain et déployer immédiatement
  - Shadow mode obligatoire: 1-2 semaines minimum
  - Paper trading validation avec capital virtuel
  - A/B testing avec allocation graduelle
  - Monitoring intensif durant transition
  - Rollback automatique si dégradation > 20% performance

Déclencheurs de retrain d'urgence:
  - Sharpe rolling 30 jours < 0.5 (du backtest 1.2)
  - Drawdown actuel > 1.5× max backtest drawdown
  - Win rate tombe < 40% (du 55% backtest)
  - Distribution shift détecté par tests KS (p < 0.01)
  - Régime persistant hors distribution training > 30 jours

================================================================================
13. DASHBOARD TEMPS RÉEL & MONITORING
================================================================================

DASHBOARD PRINCIPAL (Temps réel via SocketIO):

Section 1 - Performance Overview:
  - Equity curve live vs backtest equity overlay
  - Sharpe ratio live vs backtest (doit être dans 80%)
  - Sharpe rolling 30 jours (graphique avec seuils d'alerte)
  - Max drawdown actuel vs max backtest drawdown
  - Win rate actuel vs backtest win rate
  - Profit factor courant
  - Daily/Weekly PnL distribution overlay sur distribution backtest

Section 2 - Position & Exposure:
  - Position actuelle (size, direction, entry price)
  - Open positions avec P&L unrealized
  - Stop-loss et take-profit niveaux
  - Exposition agrégée (% du capital)
  - Leverage utilisé vs maximum autorisé
  - Marge disponible

Section 3 - Execution Quality:
  - Fill prices vs expected prices (slippage monitoring)
  - Spreads actuels vs profils historiques
  - Latence d'exécution (derniers 100 trades)
  - Coûts de transaction réels vs modèle
  - Trade frequency (trades par heure/jour)
  - Pattern changes detection

Section 4 - Regime & State:
  - Détecteur de régime: état actuel (Low Vol / High Vol)
  - Probabilités régimes: [P(low_vol), P(high_vol)]
  - Graphique historique des régimes
  - Volatilité actuelle vs distributions training
  - Session trading actuelle (Asian/European/US)
  - Spread multiplier actuel

Section 5 - Agent Ensemble:
  - Actions individuelles des 3 agents
  - Confidences des agents
  - Weights du meta-controller
  - Action agrégée finale
  - Policy entropy (doit rester 0.5-1.0)
  - Action diversity metrics

Section 6 - Risk Metrics:
  - Daily loss actuel vs limite (5%)
  - Drawdown actuel vs limite (15%)
  - Peak equity tracking
  - Value at Risk (VaR 95%)
  - Conditional VaR (CVaR)
  - Position sizing respect des limites

Section 7 - Alerts & Warnings:
  - Liste des alertes actives (Level 1, 2, 3)
  - Historique des alertes récentes
  - Status kill switch
  - Distribution shift warnings
  - Anomaly detection alerts

SEUILS CRITIQUES avec RÉPONSES AUTOMATIQUES:

Level 1 - INFO (Logging seulement):
  - Sharpe rolling 30j baisse 20% de la moyenne
  - Slippage moyen > 1.5× attendu
  - Trade frequency dévie 30% de l'attendu
  - Action: Log + notification

Level 2 - WARNING (Review requis):
  - Sharpe rolling 30j < 0.5 (du backtest 1.2)
  - Sharpe chute 50% de la moyenne récente
  - Win rate < 40% (du 55% backtest)
  - Turnover dérive > 50% de l'attendu
  - Drawdown > 1.5× max backtest drawdown
  - Tests KS de distribution: p < 0.05
  - Action: Alerte + review manuel + monitoring accru

Level 3 - CRITICAL (Action automatique):
  - Daily loss > 5%
  - Drawdown > 2× max backtest drawdown
  - Drawdown absolu > 15%
  - Equity < 20% initial capital
  - Erreur système critique
  - Action: Kill switch automatique + notification urgente

MONITORING CONTINU:

Validations quotidiennes automatiques:
  - Détecteur de régime fonctionne correctement
  - Toutes features alimentent proprement (aucune NaN)
  - Latence d'exécution < 500ms
  - Spreads matchent profils historiques ± 30%
  - Position sizing respecte limites (2% par trade)
  - Exposition agrégée dans limites définies
  - Backup models prêts pour déploiement instantané
  - Connexion MT5 stable
  - Tous pairs de devises actives

Distribution shift detection:
  Tests sur fenêtres roulantes 30 jours:
  - Test Kolmogorov-Smirnov: compare derniers 30j à training dist
    * p < 0.05 → shift détecté → Level 2 alert
  - Distance Wasserstein entre distributions
    * Distance > 2× moyenne historique → Level 2 alert
  - CUSUM tracking: déviation cumulative du mean return
    * Plus rapide que batch methods pour détecter shifts persistants

Feature-level monitoring:
  - Mean return (doit rester proche de zéro pour forex)
  - Rolling 30-day volatility vs training average
  - Correlation matrix condition number
    * Structural breaks apparaissent comme changements de corrélation
  - Higher moments: skewness et kurtosis
    * Devraient rester dans ranges historiques

Real-time dashboard refresh: 5 secondes
Metrics logging: Chaque trade + toutes les minutes
Performance evaluation: Chaque fin de journée trading
Full report generation: Hebdomadaire

================================================================================
14. MÉTRIQUES PERFORMANCE
================================================================================

Métriques primaires:

Sharpe Ratio:
  Sharpe = Mean_Return / Std_Return
  Annualized: × √(252 × 288)
  Targets: >1.5 très bon, >2.0 excellent

Sortino Ratio:
  Sortino = Mean_Return / Downside_Deviation
  Downside_Dev = std(returns < 0)
  Targets: >1.5 bon, >2.5 excellent

Calmar Ratio:
  Calmar = Annual_Return / Max_Drawdown
  Targets: >2.0 bon, >3.0 excellent

Max Drawdown:
  DD = (Peak_Equity - Current_Equity) / Peak_Equity
  Targets: <10% bon, <15% acceptable

Métriques secondaires:
- Win Rate: >50% bon
- Profit Factor: Gross_Profit / Gross_Loss, >1.5 bon
- Expectancy: (Win_Rate × Avg_Win) - (Loss_Rate × Avg_Loss), >$0
- Recovery Factor: Net_Profit / Max_DD, >3.0 bon

================================================================================
15. STRUCTURE FICHIERS
================================================================================

Projet organisé en 10 fichiers principaux:

1. data_pipeline.py
   - Téléchargement GitHub
   - Agrégation 1min→5min
   - Cleaning et alignement
   - Split train/val/test
   - Sauvegarde dataset normalisé (pickle/hdf5)

2. feature_engineering.py
   - Calcul 30 features
   - DXY synthetic
   - Normalisation expanding window
   - Validation no look-ahead
   - Cache features calculées

3. hmm_detector.py
   - GaussianHMM training
   - Regime identification
   - Viterbi decoding
   - Forward algorithm temps réel
   - Save/load model

4. trading_env.py
   - Gym environment
   - Position sizing
   - SL/TP management
   - Transaction costs (modèle décomposé)
   - Margin call logic
   - Episode management (longueurs variables)

5. sac_agent.py
   - Architecture SAC (Actor, Critic)
   - AN-SAC (Adaptive Normalization)
   - Spectral normalization
   - Training loop avec update ratio 1:1
   - Replay buffer recency-weighted
   - Checkpoint save/load
   - Support re-training depuis checkpoint

6. auxiliary_task.py
   - Autoencodeur architecture
   - K-Means clustering
   - Combined loss function
   - Pattern recognition training
   - Latent representations extraction

7. ensemble_meta.py
   - Meta-controller
   - Ensemble aggregation
   - Hindsight training
   - Load multiple agents

8. validation.py
   - Walk-forward validation
   - Statistical tests (DSR, PSR, PBO)
   - Stress tests
   - Bootstrap CI
   - OOS evaluation

9. mt5_connector.py
   - MT5 API wrapper
   - Connection management
   - Order execution
   - Position tracking
   - Market status check

10. risk_manager.py
    - Position sizing
    - Daily loss monitoring
    - Drawdown tracking
    - Kill switch logic
    - Trade validation
    - Distribution shift detection

11. web_app.py
    - Flask application
    - REST API endpoints
    - SocketIO real-time
    - HTML/CSS/JS interface complète
    - Model management (load/retrain)
    - Configuration editor
    - Dashboard temps réel

Dossiers:
/data/
  raw/              # Données brutes GitHub
  processed/        # Données agrégées 5min
  normalized/       # Dataset normalisé sauvegardé (réutilisable)
  
/models/
  checkpoints/      # Checkpoints training
  production/       # Models production actifs
  shadow/           # Models en test shadow mode
  hmm/              # HMM models
  autoencoder/      # Auxiliary task models
  
/logs/
  training/         # Logs training
  trading/          # Logs trading live
  errors/           # Error logs
  performance/      # Performance metrics daily
  
/static/            # HTML/CSS/JS web interface
/templates/         # Flask templates
/config/            # Config files (YAML)

================================================================================
16. SAUVEGARDE DATASET NORMALISÉ
================================================================================

Format: HDF5 (performant pour grands datasets)

Structure fichier normalized_dataset.h5:
/features/
  eurusd/          # 10 features EUR/USD
  dxy/             # 5 features DXY
  cross_pairs/     # 6 features cross
  risk/            # 2 features risk
  temporal/        # 7 features temporal
  
/metadata/
  timestamps       # Index temporel
  pairs_status     # Status chaque paire (actif/fermé)
  
/normalization_params/
  means            # Means expanding window
  stds             # Stds expanding window
  
/hmm/
  regime_labels    # Labels Viterbi
  regime_probs     # Probabilités forward

/auxiliary/
  latent_representations  # Features from autoencoder
  cluster_labels          # K-Means clusters

Utilisation:
1. Premier run: Calculer features + normalisation + save HDF5
2. Runs suivants: Load HDF5 directement (gain temps énorme)
3. Update: Si nouvelles données, append à HDF5
4. Validation: Checksum pour vérifier intégrité

Code:
# Save
with h5py.File('data/normalized/dataset.h5', 'w') as f:
  f.create_dataset('features/all', data=features_array)
  f.create_dataset('metadata/timestamps', data=timestamps)
  f.create_dataset('normalization_params/means', data=means)
  f.create_dataset('normalization_params/stds', data=stds)
  f.create_dataset('auxiliary/latent_representations', data=latents)

# Load
with h5py.File('data/normalized/dataset.h5', 'r') as f:
  features = f['features/all'][:]
  timestamps = f['metadata/timestamps'][:]
  means = f['normalization_params/means'][:]
  stds = f['normalization_params/stds'][:]
  latents = f['auxiliary/latent_representations'][:]

================================================================================
17. RE-TRAINING DEPUIS CHECKPOINT
================================================================================

Capability de charger un model existant pour continuer training:

Checkpoint contient:
- Actor network weights
- Critic networks weights
- Target networks weights
- Optimizer states
- Replay buffer (optionnel)
- Training step count
- Performance history
- Auxiliary task models (autoencoder + K-Means)

Process re-training:
1. Load checkpoint complet
2. Vérifier compatibilité (architecture, hyperparams)
3. Continue training depuis step actuel
4. Option: Reset replay buffer ou garder
5. Option: Réduire LR pour fine-tuning
6. Save nouveaux checkpoints avec timestamp

Interface web:
- Dropdown: Sélectionner checkpoint
- Options: Reset buffer, LR multiplier, steps additionnels
- Bouton "Start Re-training"
- Progress bar temps réel
- Validation automatique après re-training

Use cases:
- Fine-tuning sur nouvelles données
- Recovery après crash
- Exploration hyperparams différents
- Transfer learning autre timeframe

================================================================================
18. GESTION MARCHÉS FERMÉS
================================================================================

Logique détection:
1. Vérifier timestamp de dernière bar pour chaque paire
2. Si une paire: last_update > 10 minutes ago → Considérer fermée
3. Si prix inchangé pendant 5 bars consécutives → Considérer fermée
4. Maintenir status dictionary: {'EURUSD': True, 'USDJPY': False, ...}

Action si marché fermé:
- Pause trading loop
- Ne pas générer signals
- Ne pas ouvrir nouvelles positions
- Garder positions existantes (SL/TP actifs)
- Log warning
- Check status toutes les 1 minute
- Resume uniquement si TOUTES paires actives

Special cases:
- Weekend: Forex fermé vendredi 22h → lundi 00h (UTC)
- Holidays: Varie par pays (NY close, London close, etc.)
- Flash crash: Vérifier si vraiment fermé ou juste gap

Implementation:
def all_pairs_active(current_data):
  required_pairs = ['EURUSD', 'USDJPY', 'GBPUSD', ...]
  for pair in required_pairs:
    if pair not in current_data:
      return False
    last_bar = current_data[pair][-1]
    if is_stale(last_bar.timestamp) or is_unchanged(last_bar):
      return False
  return True

Notification:
- Log "Market closed, pausing trading"
- Dashboard: Afficher status "Waiting for market open"